{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu,\n",
    "                          kernel_initializer=he_init, name=\"hidden1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def leaky_relu(z, alpha=0.01):\n",
    "    return np.maximum(alpha*z, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = np.linspace(-5, 5, 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEJCAYAAAC0U81tAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120850f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, leaky_relu(z, 0.05), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([0, 0], [-0.5, 4.2], 'k-')\n",
    "plt.grid(True)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Leak', xytext=(-3.5, 0.5), xy=(-5, -0.2), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.title(\"Leaky ReLU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.5, 4.2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def leaky_relu(z, name=None):\n",
    "    return tf.maximum(0.01 * z, z, name=name)\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=leaky_relu, name=\"hidden1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=leaky_relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=leaky_relu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Batch accuracy: 0.86 Validation accuracy: 0.9044\n",
      "5 Batch accuracy: 0.94 Validation accuracy: 0.951\n",
      "10 Batch accuracy: 0.96 Validation accuracy: 0.9666\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 15\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 5 == 0:\n",
    "            acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "            acc_test = accuracy.eval(feed_dict={X: mnist.validation.images, y: mnist.validation.labels})\n",
    "            print(epoch, \"Batch accuracy:\", acc_train, \"Validation accuracy:\", acc_test)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################\n",
    "#Batch Normalization #\n",
    "######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\")\n",
    "bn1 = tf.layers.batch_normalization(hidden1, training=training, momentum=0.9)\n",
    "bn1_act = tf.nn.elu(bn1)\n",
    "\n",
    "hidden2 = tf.layers.dense(bn1_act, n_hidden2, name=\"hidden2\")\n",
    "bn2 = tf.layers.batch_normalization(hidden2, training=training, momentum=0.9)\n",
    "bn2_act = tf.nn.elu(bn2)\n",
    "\n",
    "logits_before_bn = tf.layers.dense(bn2_act, n_outputs, name=\"outputs\")\n",
    "logits = tf.layers.batch_normalization(logits_before_bn, training=training,\n",
    "                                       momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "my_batch_norm_layer = partial(tf.layers.batch_normalization,\n",
    "                              training=training, momentum=0.9)\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\")\n",
    "bn1 = my_batch_norm_layer(hidden1)\n",
    "bn1_act = tf.nn.elu(bn1)\n",
    "hidden2 = tf.layers.dense(bn1_act, n_hidden2, name=\"hidden2\")\n",
    "bn2 = my_batch_norm_layer(hidden2)\n",
    "bn2_act = tf.nn.elu(bn2)\n",
    "logits_before_bn = tf.layers.dense(bn2_act, n_outputs, name=\"outputs\")\n",
    "logits = my_batch_norm_layer(logits_before_bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "batch_norm_momentum = 0.9\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "    my_batch_norm_layer = partial(\n",
    "            tf.layers.batch_normalization,\n",
    "            training=training,\n",
    "            momentum=batch_norm_momentum)\n",
    "\n",
    "    my_dense_layer = partial(\n",
    "            tf.layers.dense,\n",
    "            kernel_initializer=he_init)\n",
    "\n",
    "    hidden1 = my_dense_layer(X, n_hidden1, name=\"hidden1\")\n",
    "    bn1 = tf.nn.elu(my_batch_norm_layer(hidden1))\n",
    "    hidden2 = my_dense_layer(bn1, n_hidden2, name=\"hidden2\")\n",
    "    bn2 = tf.nn.elu(my_batch_norm_layer(hidden2))\n",
    "    logits_before_bn = my_dense_layer(bn2, n_outputs, name=\"outputs\")\n",
    "    logits = my_batch_norm_layer(logits_before_bn)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Test accuracy: 0.8654\n",
      "1 Test accuracy: 0.8977\n",
      "2 Test accuracy: 0.9131\n",
      "3 Test accuracy: 0.9227\n",
      "4 Test accuracy: 0.9291\n",
      "5 Test accuracy: 0.9324\n",
      "6 Test accuracy: 0.9391\n",
      "7 Test accuracy: 0.9425\n",
      "8 Test accuracy: 0.9439\n",
      "9 Test accuracy: 0.9494\n"
     ]
    }
   ],
   "source": [
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run([training_op, extra_update_ops],\n",
    "                     feed_dict={training: True, X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: mnist.test.images,\n",
    "                                                y: mnist.test.labels})\n",
    "        print(epoch, \"Test accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hidden1/kernel:0',\n",
       " 'hidden1/bias:0',\n",
       " 'batch_normalization/beta:0',\n",
       " 'batch_normalization/gamma:0',\n",
       " 'hidden2/kernel:0',\n",
       " 'hidden2/bias:0',\n",
       " 'batch_normalization_1/beta:0',\n",
       " 'batch_normalization_1/gamma:0',\n",
       " 'outputs/kernel:0',\n",
       " 'outputs/bias:0',\n",
       " 'batch_normalization_2/beta:0',\n",
       " 'batch_normalization_2/gamma:0']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.name for v in tf.trainable_variables()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hidden1/kernel:0',\n",
       " 'hidden1/bias:0',\n",
       " 'batch_normalization/beta:0',\n",
       " 'batch_normalization/gamma:0',\n",
       " 'batch_normalization/moving_mean:0',\n",
       " 'batch_normalization/moving_variance:0',\n",
       " 'hidden2/kernel:0',\n",
       " 'hidden2/bias:0',\n",
       " 'batch_normalization_1/beta:0',\n",
       " 'batch_normalization_1/gamma:0',\n",
       " 'batch_normalization_1/moving_mean:0',\n",
       " 'batch_normalization_1/moving_variance:0',\n",
       " 'outputs/kernel:0',\n",
       " 'outputs/bias:0',\n",
       " 'batch_normalization_2/beta:0',\n",
       " 'batch_normalization_2/gamma:0',\n",
       " 'batch_normalization_2/moving_mean:0',\n",
       " 'batch_normalization_2/moving_variance:0']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.name for v in tf.global_variables()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "#Gradient Clipping    #\n",
    "#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_hidden3 = 50\n",
    "n_hidden4 = 50\n",
    "n_hidden5 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\")\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\")\n",
    "    hidden5 = tf.layers.dense(hidden4, n_hidden5, activation=tf.nn.relu, name=\"hidden5\")\n",
    "    logits = tf.layers.dense(hidden5, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "threshold = 1.0\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "capped_gvs = [(tf.clip_by_value(grad, -threshold, threshold), var)\n",
    "              for grad, var in grads_and_vars]\n",
    "training_op = optimizer.apply_gradients(capped_gvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Test accuracy: 0.3086\n",
      "1 Test accuracy: 0.7973\n",
      "2 Test accuracy: 0.8805\n",
      "3 Test accuracy: 0.9029\n",
      "4 Test accuracy: 0.9127\n",
      "5 Test accuracy: 0.92\n",
      "6 Test accuracy: 0.9235\n",
      "7 Test accuracy: 0.9302\n",
      "8 Test accuracy: 0.9335\n",
      "9 Test accuracy: 0.9381\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: mnist.test.images,\n",
    "                                                y: mnist.test.labels})\n",
    "        print(epoch, \"Test accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
